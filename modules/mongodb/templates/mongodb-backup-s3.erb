#!/usr/bin/env python
from datetime import datetime
import boto3
import json
import random
import os
import shutil
import subprocess
import sys
import time

############################################
# Variables
############################################
backup_dir = '<%= @backup_dir %>'
date_format = '%Y-%m-%d:%H:%M:%S'
mongo_server = '<%= @server %>'
key_fingerprint = '<%= @private_gpg_key_fingerprint %>'
s3_bucket = '<%= @s3_bucket %>'
start_time = time.time()
today = datetime.today().strftime('%Y-%m-%d')
############################################

def logger(str):
    print datetime.now().strftime(date_format) + ': ' + str

def get_mongo_nodes():
    logger('Find Secondary Mongo members')
    try:
        mongo_nodes = subprocess.check_output(["mongo",  mongo_server, "--quiet", "--eval", "printjson(rs.status().members.map(function(m) { return {'name':m.name, 'stateStr':m.stateStr} }))"])
    except OSError:
        sys.exit('Trouble querying mongo server: %s' % mongo_server)

    nodes = json.loads(mongo_nodes)
    secondary_nodes = { x["name"] for x in nodes if x["stateStr"] == "SECONDARY" }

    if secondary_nodes:
      backup_nodes = random.sample(secondary_nodes,1)
    else:
      backup_nodes = ['localhost']

    backup_node = backup_nodes[0]
    return backup_node

def backup_mongo(node):
    logger('Start mongo backup')
    try:
        subprocess.call(['mongodump', '-h', node, '-o', backup_dir])
    except OSError:
        sys.exit('There was a problem backing up the mongo database')
    logger('End mongo backup')

def get_subdirs(parent):
    subdirs = os.listdir(parent)
    return subdirs

def compress_and_encrypt(backup_dir, dir):
    logger('Start compress and encrypt backups for %s' % dir)
    subdir = backup_dir + '/' + str(dir)
    enc_file = backup_dir + '/' + str(dir) + '.tar.gz.gpg'
    try:
        tar = subprocess.Popen(['tar', '-cvz', subdir], stdout=subprocess.PIPE)
        gpg = subprocess.Popen(['gpg', '-e', '-o', str(enc_file) , '-r', key_fingerprint, '--cipher-algo', 'AES256', '--force-mdc'], stdin=tar.stdout, stdout=subprocess.PIPE)
        tar.stdout.close()
        gpg.communicate()
    except OSError as e:
        sys.exit('There was a problem compressing and encrypting the database')
    logger('End compress and encrypt backups for %s' % dir)

def push_to_s3(backup_dir, dir):
    try:
        enc_file = str(dir) + '.tar.gz.gpg'
        logger('Start upload file %s to S3' % enc_file)
        s3 = boto3.resource('s3')
        s3_key = str(today) + '/' + str(enc_file)
        source = backup_dir + '/' + str(enc_file)
        s3.Object(s3_bucket, s3_key).put(Body=open(source, 'rb'))
        logger('End upload file %s to S3' % enc_file)
    except Exception as e:
        sys.exit(e)

def cleanup_local():
    try:
        backup_dir
    except NameError:
        print "%s not defined" % backup_dir
    else:
        logger('Start cleanup of %s' % backup_dir)

    if backup_dir not in ['','/']:
        rm_tree = backup_dir + '/'
        try:
            shutil.rmtree(rm_tree, ignore_errors=True)
            print 'Cleaned up %s' % rm_tree
        except Exception as e:
            sys.exit(e)
    logger('End cleanup filesystem')

def get_run_time():
    end_time = time.time()
    delta = round((end_time - start_time), 2)
    run_time = "Script completed in " + str(delta) + " seconds."
    return run_time

cleanup_local()

backup_node = get_mongo_nodes()
backup_mongo(backup_node)

subdirs = get_subdirs(backup_dir)
logger('*** Start Compress and Encrypt ***')
for dir in subdirs:
    compress_and_encrypt(backup_dir, dir)
logger('*** End Compress and Encrypt ***')

logger('*** Start upload to S3 ***')
for file in subdirs:
    push_to_s3(backup_dir, file)
logger('*** End upload to S3 ***')

get_run_time()
